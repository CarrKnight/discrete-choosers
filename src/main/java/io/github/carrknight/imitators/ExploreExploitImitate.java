package io.github.carrknight.imitators;

import com.sun.javafx.UnmodifiableArrayList;
import io.github.carrknight.Chooser;
import io.github.carrknight.Observation;
import io.github.carrknight.utils.DiscreteChoosersUtilities;
import io.github.carrknight.utils.RewardFunction;
import io.github.carrknight.utils.rules.ObservationPredicate;
import javafx.util.Pair;
import org.jetbrains.annotations.Nullable;

import java.util.Arrays;
import java.util.SplittableRandom;
import java.util.function.Function;

public class ExploreExploitImitate<O,R,C> implements Chooser<O,R,C> {


    /**
     * contains our favorite location so far
     */
    private ExploreExplotImitateState<O,R,C> state;

    private O lastChoiceMade;

    /**
     * judges utilities
     */
    private RewardFunction<O,R,C> rewardFunction;

    /**
     * keeps track of what my last decision was; handy for diagnostics mostly
     */
    private ExploreExploitImitateAction lastAction = ExploreExploitImitateAction.INITIALIZING;


    /**
     * keeps track of what options are available
     */
    private UnmodifiableArrayList<O> optionsAvailable;


    /**
     * when should we explore?
     */
    private ObservationPredicate<O,R,C> explorationRule;

    /**
     * when should we exploit?
     */
    private ObservationPredicate<O,R,C> imitationRule;


    private SplittableRandom random;


    /**
     * rule to decide how to explore when asked to do so
     */
    private ExplorationStep<O,R,C> explorer;


    public ExploreExploitImitate(
            RewardFunction<O, R, C> rewardFunction,
            O[] optionsAvailable,
            ObservationPredicate<O, R, C> explorationRule,
            ObservationPredicate<O, R, C> imitationRule,
            SplittableRandom random,
            ExplorationStep<O, R, C> explorer) {
        this.rewardFunction = rewardFunction;
        this.optionsAvailable = new UnmodifiableArrayList<>(optionsAvailable,
                                                            optionsAvailable.length);
        this.explorationRule = explorationRule;
        this.imitationRule = imitationRule;
        this.random = random;
        this.explorer = explorer;
        lastChoiceMade = this.optionsAvailable.get(random.nextInt(this.optionsAvailable.size()));
        state = new ExploreExplotImitateState<>(lastChoiceMade,null);
    }

    /**
     * this is a simple getter that returns what the last choice made was. *this does not update choices*
     *
     * @return
     */
    @Override
    public O getLastChoice() {

        return lastChoiceMade;


    }


    /**
     * the main method of the chooser. It does two things at once:
     * * Receives new information given a previous action (and possibly additional information from observing others)
     * * Picks a new O for next step and return it
     *
     * @param observation            the reward and action taken last (can be null if experiment wasn't valid)
     * @param additionalObservations additional action-rewards observed (by imitation or whatever)
     * @return O chosen to play next
     */
    @SafeVarargs
    @Override
    public final O updateAndChoose(
            @Nullable Observation<O, R, C> observation,
            Observation<O, R, C>... additionalObservations) {


        //first, update your favorite spot given the new observation
        if(observation!=null)
            state=state.resolve(observation,
                                rewardFunction);

        //if initialization has failed, try again
        if(state.getFavoriteResult()==null)
        {
            lastAction = ExploreExploitImitateAction.INITIALIZING;
            state = new ExploreExplotImitateState<>(
                    optionsAvailable.get(random.nextInt(optionsAvailable.size())),
                    null
            );
            lastChoiceMade = state.getFavoriteOption();
            return lastChoiceMade;
        }

        assert state.getFavoriteResult() != null;

        //explore?
        if(explorationRule.shouldExplore(
                observation,
                getLastChoice(),
                rewardFunction,
                random,
                additionalObservations)) {
            //explore

            lastChoiceMade = explorer.explore(optionsAvailable,
                                         getLastChoice(),
                                         random);
            lastAction = ExploreExploitImitateAction.EXPLORING;

            return lastChoiceMade;
        }

        //should I imitate?
        if(additionalObservations.length >0 &&
                imitationRule.shouldExplore(
                observation,
                getLastChoice(),
                rewardFunction,
                random,
                additionalObservations)) {
            //imitate
            C context = observation != null ? observation.getContext() : null;
            double currentReward = rewardFunction.extractUtility(
                    state.getFavoriteOption(),
                    state.getFavoriteResult(),
                    context
            );

            Pair<Observation<O, R, C>,Double> bestObservation = DiscreteChoosersUtilities.getBestOption(
                    Arrays.asList(additionalObservations),
                    new Function<Observation<O, R, C>, Double>() {
                        @Override
                        public Double apply(Observation<O, R, C> observation) {
                            return rewardFunction.extractUtility(
                                    observation.getChoiceMade(),
                                    observation.getResultObserved(),
                                    observation.getContext()
                            );
                        }
                    },
                    random,
                    currentReward
            );
            //if there is anything good to copy!
            if(bestObservation != null)
            {
                lastAction = ExploreExploitImitateAction.IMITATING;
                lastChoiceMade = bestObservation.getKey().getChoiceMade();
                return lastChoiceMade;
            }


        }

        //otherwise exploit!
        lastAction=ExploreExploitImitateAction.EXPLOITING;
        return state.getFavoriteOption();


    }

    /**
     * Getter for property 'state'.
     *
     * @return Value for property 'state'.
     */
    public ExploreExplotImitateState<O, R, C> getState() {
        return state;
    }

    /**
     * Getter for property 'rewardFunction'.
     *
     * @return Value for property 'rewardFunction'.
     */
    public RewardFunction<O, R, C> getRewardFunction() {
        return rewardFunction;
    }

    /**
     * Setter for property 'rewardFunction'.
     *
     * @param rewardFunction Value to set for property 'rewardFunction'.
     */
    public void setRewardFunction(RewardFunction<O, R, C> rewardFunction) {
        this.rewardFunction = rewardFunction;
    }

    /**
     * Getter for property 'lastAction'.
     *
     * @return Value for property 'lastAction'.
     */
    public ExploreExploitImitateAction getLastAction() {
        return lastAction;
    }


    /**
     * Getter for property 'optionsAvailable'.
     *
     * @return Value for property 'optionsAvailable'.
     */
    public UnmodifiableArrayList<O> getOptionsAvailable() {
        return optionsAvailable;
    }

    /**
     * Setter for property 'optionsAvailable'.
     *
     * @param optionsAvailable Value to set for property 'optionsAvailable'.
     */
    public void setOptionsAvailable(UnmodifiableArrayList<O> optionsAvailable) {
        this.optionsAvailable = optionsAvailable;
    }

    /**
     * Setter for property 'state'.
     *
     * @param state Value to set for property 'state'.
     */
    public void setState(ExploreExplotImitateState<O, R, C> state) {
        this.state = state;
    }

    /**
     * Getter for property 'explorationRule'.
     *
     * @return Value for property 'explorationRule'.
     */
    public ObservationPredicate<O, R, C> getExplorationRule() {
        return explorationRule;
    }

    /**
     * Setter for property 'explorationRule'.
     *
     * @param explorationRule Value to set for property 'explorationRule'.
     */
    public void setExplorationRule(ObservationPredicate<O, R, C> explorationRule) {
        this.explorationRule = explorationRule;
    }

    /**
     * Getter for property 'imitationRule'.
     *
     * @return Value for property 'imitationRule'.
     */
    public ObservationPredicate<O, R, C> getImitationRule() {
        return imitationRule;
    }

    /**
     * Setter for property 'imitationRule'.
     *
     * @param imitationRule Value to set for property 'imitationRule'.
     */
    public void setImitationRule(ObservationPredicate<O, R, C> imitationRule) {
        this.imitationRule = imitationRule;
    }

    /**
     * Getter for property 'random'.
     *
     * @return Value for property 'random'.
     */
    public SplittableRandom getRandom() {
        return random;
    }

    /**
     * Setter for property 'random'.
     *
     * @param random Value to set for property 'random'.
     */
    public void setRandom(SplittableRandom random) {
        this.random = random;
    }

    /**
     * Getter for property 'explorer'.
     *
     * @return Value for property 'explorer'.
     */
    public ExplorationStep<O, R, C> getExplorer() {
        return explorer;
    }

    /**
     * Setter for property 'explorer'.
     *
     * @param explorer Value to set for property 'explorer'.
     */
    public void setExplorer(ExplorationStep<O, R, C> explorer) {
        this.explorer = explorer;
    }


}
